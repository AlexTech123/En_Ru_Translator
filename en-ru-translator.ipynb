{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2345761,"sourceType":"datasetVersion","datasetId":1416132}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom collections import Counter\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-14T05:38:26.229369Z","iopub.execute_input":"2024-09-14T05:38:26.230216Z","iopub.status.idle":"2024-09-14T05:38:31.180381Z","shell.execute_reply.started":"2024-09-14T05:38:26.230172Z","shell.execute_reply":"2024-09-14T05:38:31.179336Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:38:31.182275Z","iopub.execute_input":"2024-09-14T05:38:31.182816Z","iopub.status.idle":"2024-09-14T05:38:31.322839Z","shell.execute_reply.started":"2024-09-14T05:38:31.182772Z","shell.execute_reply":"2024-09-14T05:38:31.321780Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:38:31.324077Z","iopub.execute_input":"2024-09-14T05:38:31.324420Z","iopub.status.idle":"2024-09-14T05:38:31.364884Z","shell.execute_reply.started":"2024-09-14T05:38:31.324387Z","shell.execute_reply":"2024-09-14T05:38:31.363706Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"text = \"/kaggle/input/englishrussian-dictionary-for-machine-translate/rus.txt\"\n\nwith open(text) as file:\n    lines = file.read().split(\"\\n\")[:-1]\npairs = []\n\nfor line in lines:\n    english, russian = line.split(\"\\t\")[:2]\n    russian = russian\n    pairs.append((english, russian))","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:38:31.368014Z","iopub.execute_input":"2024-09-14T05:38:31.369023Z","iopub.status.idle":"2024-09-14T05:38:32.855317Z","shell.execute_reply.started":"2024-09-14T05:38:31.368979Z","shell.execute_reply":"2024-09-14T05:38:32.854271Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(pairs)\ndf.columns = ['en', 'ru']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:38:32.856553Z","iopub.execute_input":"2024-09-14T05:38:32.856949Z","iopub.status.idle":"2024-09-14T05:38:32.961073Z","shell.execute_reply.started":"2024-09-14T05:38:32.856904Z","shell.execute_reply":"2024-09-14T05:38:32.960050Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    en             ru\n0  Go.          Марш!\n1  Go.           Иди.\n2  Go.         Идите.\n3  Hi.  Здравствуйте.\n4  Hi.        Привет!","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>ru</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Марш!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>Иди.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Go.</td>\n      <td>Идите.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hi.</td>\n      <td>Здравствуйте.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hi.</td>\n      <td>Привет!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"vocab_en = set(['<unk>', '<bos>', '<eos>', '<pad>'])\nvocab_ru = set(['<unk>', '<bos>', '<eos>', '<pad>'])\n\nfor sentence in tqdm(df['en']):\n    for word in word_tokenize(sentence):\n        vocab_en.add(word)\n        \nfor sentence in tqdm(df['ru']):\n    for word in word_tokenize(sentence):\n        vocab_ru.add(word)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:38:32.962511Z","iopub.execute_input":"2024-09-14T05:38:32.962938Z","iopub.status.idle":"2024-09-14T05:40:08.369061Z","shell.execute_reply.started":"2024-09-14T05:38:32.962893Z","shell.execute_reply":"2024-09-14T05:40:08.368151Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/363386 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63fa9740748d40dfb734aea646f5b3f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/363386 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d742cda69d4a3fb81bd0ce6b85d795"}},"metadata":{}}]},{"cell_type":"code","source":"word2ind_en = {char: i for i, char in enumerate(vocab_en)}\nind2word_en = {i: char for char, i in word2ind_en.items()}\n\nword2ind_ru = {char: i for i, char in enumerate(vocab_ru)}\nind2word_ru = {i: char for char, i in word2ind_ru.items()}","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.370229Z","iopub.execute_input":"2024-09-14T05:40:08.370503Z","iopub.status.idle":"2024-09-14T05:40:08.414379Z","shell.execute_reply.started":"2024-09-14T05:40:08.370473Z","shell.execute_reply":"2024-09-14T05:40:08.413375Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SentDataset(Dataset):\n    def __init__(self, sentences_en, sentences_ru):\n        self.sentences_en = sentences_en\n        self.sentences_ru = sentences_ru\n        \n        self.unk_id_en = word2ind_en['<unk>']\n        self.bos_id_en = word2ind_en['<bos>']\n        self.eos_id_en = word2ind_en['<eos>']\n        self.pad_id_en = word2ind_en['<pad>']\n        \n        self.unk_id_ru = word2ind_ru['<unk>']\n        self.bos_id_ru = word2ind_ru['<bos>']\n        self.eos_id_ru = word2ind_ru['<eos>']\n        self.pad_id_ru = word2ind_ru['<pad>']\n        \n    def __getitem__(self, idx):\n        tokenized_sentence_en = [self.bos_id_en]\n        tokenized_sentence_en += [word2ind_en.get(word, self.unk_id_en) for word in word_tokenize(self.sentences_en[idx])]\n        tokenized_sentence_en += [self.eos_id_en]\n        \n        tokenized_sentence_ru = [self.bos_id_ru]\n        tokenized_sentence_ru += [word2ind_ru.get(word, self.unk_id_ru) for word in word_tokenize(self.sentences_ru[idx])]\n        tokenized_sentence_ru += [self.eos_id_ru]\n        \n        return (tokenized_sentence_en, tokenized_sentence_ru)\n    \n    def __len__(self):\n        return len(self.sentences_en)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.415674Z","iopub.execute_input":"2024-09-14T05:40:08.416066Z","iopub.status.idle":"2024-09-14T05:40:08.425498Z","shell.execute_reply.started":"2024-09-14T05:40:08.416021Z","shell.execute_reply":"2024-09-14T05:40:08.424662Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def collate_fn_with_padding(batch):\n    sentences_en, sentences_ru = zip(*batch)\n    \n    max_len_en = max(len(sentence) for sentence in sentences_en)\n    max_len_ru = max(len(sentence) for sentence in sentences_ru)\n    \n    padded_sentences_en = [sentence + [word2ind_en['<pad>']] * (max_len_en - len(sentence)) for sentence in sentences_en]\n    padded_sentences_ru = [sentence + [word2ind_ru['<pad>']] * (max_len_ru - len(sentence)) for sentence in sentences_ru]\n    \n    mask_en = [[0.0] * len(sentence) + [-float('inf')] * (max_len_en - len(sentence)) for sentence in sentences_en]\n    mask_ru = [[0.0] * len(sentence) + [-float('inf')] * (max_len_ru - len(sentence)) for sentence in sentences_ru]\n    \n    padded_sentences_en = torch.tensor(padded_sentences_en, dtype=torch.long, device=device)\n    padded_sentences_ru = torch.tensor(padded_sentences_ru, dtype=torch.long, device=device)\n    \n    mask_en = torch.tensor(mask_en, dtype=torch.float, device=device)\n    mask_ru = torch.tensor(mask_ru, dtype=torch.float, device=device)\n    \n    return padded_sentences_en, padded_sentences_ru, mask_en, mask_ru\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.426593Z","iopub.execute_input":"2024-09-14T05:40:08.427165Z","iopub.status.idle":"2024-09-14T05:40:08.439490Z","shell.execute_reply.started":"2024-09-14T05:40:08.427131Z","shell.execute_reply":"2024-09-14T05:40:08.438576Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_en, test_en, train_ru, test_ru = train_test_split(\n    df['en'].tolist(),\n    df['ru'].tolist(),\n    test_size=0.2\n)\n\ntrain_dataset = SentDataset(train_en, train_ru)\ntest_dataset = SentDataset(test_en, test_ru)\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_fn_with_padding\n)\n\ntest_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_fn_with_padding\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.442682Z","iopub.execute_input":"2024-09-14T05:40:08.443059Z","iopub.status.idle":"2024-09-14T05:40:08.704322Z","shell.execute_reply.started":"2024-09-14T05:40:08.443026Z","shell.execute_reply":"2024-09-14T05:40:08.703518Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, vocab_size_en, vocab_size_ru, d_model=256, nhead=4, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=512, dropout=0.1):\n        super(TransformerModel, self).__init__()\n        \n        self.embedding_en = nn.Embedding(vocab_size_en, d_model)\n        self.embedding_ru = nn.Embedding(vocab_size_ru, d_model)\n        \n        self.positional_encoding_en = PositionalEncoding(d_model, dropout)\n        self.positional_encoding_ru = PositionalEncoding(d_model, dropout)\n        \n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward, dropout=dropout,\n            batch_first=True\n        )\n        \n        self.fc_out = nn.Linear(d_model, vocab_size_ru)\n        \n    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask):\n        src_emb = self.embedding_en(src)\n            \n        src_emb = self.positional_encoding_en(src_emb)\n        \n        tgt_emb = self.embedding_ru(tgt)\n            \n        tgt_emb = self.positional_encoding_ru(tgt_emb)\n        \n        transformer_output = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, src_key_padding_mask=src_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n        \n        output = self.fc_out(transformer_output)\n        \n        return output\n    \n    \nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=0.1, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.705427Z","iopub.execute_input":"2024-09-14T05:40:08.705719Z","iopub.status.idle":"2024-09-14T05:40:08.741544Z","shell.execute_reply.started":"2024-09-14T05:40:08.705688Z","shell.execute_reply":"2024-09-14T05:40:08.740653Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    running_loss = 0\n    num_batches = len(dataloader)\n    \n    with tqdm(total=num_batches, desc=\"Training\", unit=\"batch\") as pbar:\n        for i, batch in enumerate(dataloader):\n            src, tgt, src_padding_mask, tgt_padding_mask = batch\n            \n            src = src.to(device)\n            tgt_input = tgt[:, :-1].to(device)\n            tgt_output = tgt[:, 1:].to(device)\n            \n            src_padding_mask = src_padding_mask.to(device)\n            tgt_padding_mask = tgt_padding_mask[:, :-1].to(device)\n            \n            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n            \n            optimizer.zero_grad()\n            \n            output = model(src, tgt_input, None, tgt_mask, src_padding_mask, tgt_padding_mask)\n            \n            output = output.view(-1, output.size(-1))\n            tgt_output = tgt_output.reshape(-1)\n            \n            loss = criterion(output, tgt_output)\n            \n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            running_loss += loss.item()\n            \n            if (i + 1) % 50 == 0:\n                pbar.set_postfix({'loss': running_loss / 50})\n                running_loss = 0\n            \n            pbar.update(1)\n        \n    return total_loss / num_batches\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.742821Z","iopub.execute_input":"2024-09-14T05:40:08.743133Z","iopub.status.idle":"2024-09-14T05:40:08.755335Z","shell.execute_reply.started":"2024-09-14T05:40:08.743102Z","shell.execute_reply":"2024-09-14T05:40:08.754549Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            src, tgt, src_padding_mask, tgt_padding_mask = batch\n        \n            src = src.to(device)\n            tgt_input = tgt[:, :-1].to(device)\n            tgt_output = tgt[:, 1:].to(device)\n\n            src_padding_mask = src_padding_mask.to(device)\n            tgt_padding_mask = tgt_padding_mask[:, :-1].to(device)\n\n            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n\n            output = model(src, tgt_input, None, tgt_mask, src_padding_mask, tgt_padding_mask)\n\n            output = output.view(-1, output.size(-1))\n            tgt_output = tgt_output.reshape(-1)\n\n            loss = criterion(output, tgt_output)\n\n            total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.756461Z","iopub.execute_input":"2024-09-14T05:40:08.756803Z","iopub.status.idle":"2024-09-14T05:40:08.768137Z","shell.execute_reply.started":"2024-09-14T05:40:08.756761Z","shell.execute_reply":"2024-09-14T05:40:08.767396Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs):\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n        val_loss = evaluate(model, val_loader, criterion, device)\n        \n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n        \n        torch.save(model.state_dict(), f'model_epoch_{epoch + 1}')\n    \n    return train_losses, val_losses\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.769241Z","iopub.execute_input":"2024-09-14T05:40:08.769992Z","iopub.status.idle":"2024-09-14T05:40:08.778653Z","shell.execute_reply.started":"2024-09-14T05:40:08.769950Z","shell.execute_reply":"2024-09-14T05:40:08.777905Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = TransformerModel(\n    vocab_size_en=len(vocab_en), \n    vocab_size_ru=len(vocab_ru),\n    \n)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:08.779597Z","iopub.execute_input":"2024-09-14T05:40:08.779909Z","iopub.status.idle":"2024-09-14T05:40:09.461460Z","shell.execute_reply.started":"2024-09-14T05:40:08.779878Z","shell.execute_reply":"2024-09-14T05:40:09.460665Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"num_params = sum(p.numel() for p in model.parameters())\nparam_size_bytes = 4\ntotal_size_bytes = num_params * param_size_bytes\ntotal_size_megabytes = total_size_bytes / (1024 ** 2)\nprint(f\"Размер модели: {total_size_megabytes:.2f} МБ\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:09.462566Z","iopub.execute_input":"2024-09-14T05:40:09.462881Z","iopub.status.idle":"2024-09-14T05:40:09.468796Z","shell.execute_reply.started":"2024-09-14T05:40:09.462849Z","shell.execute_reply":"2024-09-14T05:40:09.467912Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Размер модели: 144.79 МБ\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters())\n\ncriterion = nn.CrossEntropyLoss(ignore_index=word2ind_ru['<pad>'])","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:09.469802Z","iopub.execute_input":"2024-09-14T05:40:09.470112Z","iopub.status.idle":"2024-09-14T05:40:10.485111Z","shell.execute_reply.started":"2024-09-14T05:40:09.470081Z","shell.execute_reply":"2024-09-14T05:40:10.484271Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_losses, val_losses = train(model, train_loader, test_loader, optimizer, criterion, device, 6)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:40:10.486243Z","iopub.execute_input":"2024-09-14T05:40:10.486680Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2272 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82a2877d9e954923992fa393bd09ff59"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:409: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/6, Train Loss: 3.1451, Val Loss: 2.2708\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2272 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f37888268e54ea880ec7c06ce87b22e"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/6, Train Loss: 1.8746, Val Loss: 1.7220\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2272 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f5c14939a714e3aa4b3f7267dfcf0d4"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/6, Train Loss: 1.4628, Val Loss: 1.5943\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2272 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"454b4dac50574dab902005ac15351f35"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/6, Train Loss: 1.2417, Val Loss: 1.5260\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2272 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"159ad0ff100846708fa921204a6c4efa"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/6, Train Loss: 1.1023, Val Loss: 1.5060\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2272 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f9c8df9bb6246eab01bbed0957355ee"}},"metadata":{}}]},{"cell_type":"markdown","source":"**val loss:** $1.57$","metadata":{}},{"cell_type":"code","source":"def translate_sentence(model, sentence, max_len=50):\n    model.eval()\n\n    tokens = [word2ind_en.get(word, word2ind_en['<unk>']) for word in word_tokenize(sentence)]\n    \n    tokens = [word2ind_en['<bos>']] + tokens + [word2ind_en['<eos>']]\n\n    src = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n    \n    src_mask = torch.zeros((1, 1, src.size(1)), device=device)\n\n    memory = model.transformer.encoder(model.positional_encoding_en(model.embedding_en(src)))\n\n    tgt_tokens = [word2ind_ru['<bos>']]\n    \n    for _ in range(max_len):\n        tgt_input = torch.tensor(tgt_tokens, dtype=torch.long).unsqueeze(0).to(device)\n        \n        tgt_mask = nn.Transformer.generate_square_subsequent_mask(len(tgt_input[0])).to(device)\n        \n        output = model.transformer.decoder(\n            model.positional_encoding_ru(model.embedding_ru(tgt_input)),\n            memory,\n            tgt_mask=tgt_mask\n        )\n\n        output = model.fc_out(output[:, -1, :])\n        predicted_token = output.argmax(dim=1).item()\n        \n        tgt_tokens.append(predicted_token)\n        \n        if predicted_token == word2ind_ru['<eos>']:\n            break\n\n    translated_sentence = [ind2word_ru[token] for token in tgt_tokens if token not in {word2ind_ru['<bos>'], word2ind_ru['<eos>'], word2ind_ru['<pad>']}]\n    \n    return \" \".join(translated_sentence)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translate_sentence(model, 'you are too late today')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = 'model_final.pth'\nword2ind_en_path = 'word2ind_en.pth'\nind2word_en_path = 'ind2word_en.pth'\nword2ind_ru_path = 'word2ind_ru.pth'\nind2word_ru_path = 'ind2word_ru.pth'\n\ntorch.save(model.state_dict(), model_path)\ntorch.save(word2ind_en, word2ind_en_path)\ntorch.save(ind2word_en, ind2word_en_path)\ntorch.save(word2ind_ru, word2ind_ru_path)\ntorch.save(ind2word_ru, ind2word_ru_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}